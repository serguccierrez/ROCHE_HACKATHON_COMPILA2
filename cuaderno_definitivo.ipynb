{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-04T18:01:31.455395Z",
     "iopub.status.busy": "2025-11-04T18:01:31.455040Z",
     "iopub.status.idle": "2025-11-04T18:01:34.660036Z",
     "shell.execute_reply": "2025-11-04T18:01:34.657130Z",
     "shell.execute_reply.started": "2025-11-04T18:01:31.455369Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/3543197335.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0murl_completa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_list_endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_completa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_consulta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 5. Comprueba si la petici√≥n fue exitosa (c√≥digo 200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    645\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time \n",
    "\n",
    "BASE_URL = \"https://api.hackupm2025.workers.dev\"\n",
    "train_list_endpoint = \"/api/v1/patients/train\"\n",
    "i = 1\n",
    "lista=[]\n",
    "while True:\n",
    "    try:\n",
    "        params_consulta = {\n",
    "            'page': i,\n",
    "            'limit': 20,\n",
    "        }\n",
    "\n",
    "        url_completa = BASE_URL + train_list_endpoint\n",
    "\n",
    "        response = requests.get(url_completa, params=params_consulta, timeout=10)\n",
    "\n",
    "        # 5. Comprueba si la petici√≥n fue exitosa (c√≥digo 200)\n",
    "        if response.status_code == 200:\n",
    "            datos = response.json()\n",
    "            # print(f\"URL final solicitada: {response.url}\")\n",
    "            for fila in datos['data']:\n",
    "                lista.append((fila['patient_id'], fila['has_diabetes'], fila['medical_note']))\n",
    "            # (Opcional) Muestra cu√°ntos datos reales vinieron\n",
    "            # Asumiendo que los datos est√°n en una clave 'data')\n",
    "            \n",
    "            # ---\n",
    "            # 1. CORRECCI√ìN DE SINTAXIS Y L√ìGICA:\n",
    "            #    Mueve el 'break' DENTRO del if de √©xito.\n",
    "            #    Corrige la sintaxis de acceso al diccionario.\n",
    "            #    Compara con el booleano 'False', no con el string \"false\".\n",
    "            # ---\n",
    "            if not datos[\"pagination\"][\"hasNextPage\"]:\n",
    "                print(\"No hay m√°s p√°ginas. Saliendo del bucle.\")\n",
    "                break # ¬°√âxito! Salimos del bucle.\n",
    "            \n",
    "            # Si llegamos aqu√≠, es que hay m√°s p√°ginas. Incrementamos.\n",
    "            i += 1\n",
    "\n",
    "        else:\n",
    "            # 2. CORRECCI√ìN DE ERROR:\n",
    "            #    Si la API da un error (ej. 404, 500), debemos parar el bucle.\n",
    "            print(f\"Error: La API devolvi√≥ el c√≥digo {response.status_code}\")\n",
    "            print(f\"Respuesta: {response.text}\")\n",
    "            print(\"Saliendo del bucle debido a un error de la API.\")\n",
    "            break # Salimos del bucle si la API falla\n",
    "\n",
    "    # 3. CORRECCI√ìN DE EXCEPCI√ìN:\n",
    "    #    La sintaxis 'Exception or ...' es incorrecta.\n",
    "    #    Es mejor capturar la excepci√≥n base de 'requests'.\n",
    "    except requests.exceptions.RequestException as e: \n",
    "        print(f\"Error de conexi√≥n o red: {e}\")\n",
    "        print(f\"No se pudo conectar a '{BASE_URL}'. Saliendo del bucle.\")\n",
    "        break # Salimos si hay un error de conexi√≥n\n",
    "\n",
    "    # A√±ade una peque√±a pausa para no saturar la API\n",
    "    #time.sleep(0.5)\n",
    "\n",
    "print(\"¬°Datos de entrenamiento obtenidos con √©xito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.660486Z",
     "iopub.status.idle": "2025-11-04T18:01:34.660743Z",
     "shell.execute_reply": "2025-11-04T18:01:34.660630Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.660618Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.661379Z",
     "iopub.status.idle": "2025-11-04T18:01:34.661694Z",
     "shell.execute_reply": "2025-11-04T18:01:34.661574Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.661557Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nltk svgling\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.663035Z",
     "iopub.status.idle": "2025-11-04T18:01:34.663325Z",
     "shell.execute_reply": "2025-11-04T18:01:34.663179Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.663169Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install medspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.664738Z",
     "iopub.status.idle": "2025-11-04T18:01:34.665020Z",
     "shell.execute_reply": "2025-11-04T18:01:34.664906Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.664894Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Span\n",
    "from loguru import logger\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "logger.disable(\"PyRuSH\")\n",
    "logger.disable(\"medspacy\")\n",
    "\n",
    "# ---  Cargar modelo base de spaCy con POS tagging ---\n",
    "base_nlp = spacy.load(\"en_core_web_sm\")  # o \"es_core_news_sm\" si es espa√±ol\n",
    "\n",
    "# ---  Integrar MedSpaCy SOBRE ese modelo y guardar el resultado ---\n",
    "nlp = medspacy.load(enable=[\"target_matcher\", \"context\"], nlp=base_nlp)\n",
    "\n",
    "print(\"Pipeline despu√©s de cargar MedSpaCy:\", nlp.pipe_names)\n",
    "\n",
    "# ---  A√±adir tus reglas de entidades cl√≠nicas ---\n",
    "target_rules = [\n",
    "    TargetRule(\"HbA1c\", \"MARKER\"),\n",
    "    TargetRule(\"BMI\", \"BMI\"),\n",
    "    TargetRule(\"glucose\", \"GLUCOSE\"),\n",
    "    TargetRule(\"year\", \"AGE\"),\n",
    "    TargetRule(\"female\", \"GENDER\"),\n",
    "    TargetRule(\"male\", \"GENDER\"),\n",
    "\n",
    "    # Para determinar fumadores\n",
    "    TargetRule(\"smoker\", \"SMOKE\"),\n",
    "    TargetRule(\"smoke\", \"SMOKE\"),\n",
    "    TargetRule(\"smoking\", \"SMOKE\"),\n",
    "    TargetRule(\"smokin\", \"SMOKE\"),\n",
    "\n",
    "    # Hipertensi√≥n\n",
    "    TargetRule(\"hypertension\", \"HYPERTENSION\"),\n",
    "    TargetRule(\"hypertensive\", \"HYPERTENSION\"),\n",
    "    TargetRule(\"high blood pressure\", \"HYPERTENSION\"),\n",
    "    TargetRule(\"HTN\", \"HYPERTENSION\"),\n",
    "\n",
    "    TargetRule(\"heart disease\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"coronary artery disease\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"ischemic heart disease\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"cardiovascular disease\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"CVD\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"IHD\", \"HEART_DISEASE\"),\n",
    "    TargetRule(\"CAD\", \"HEART_DISEASE\"),\n",
    "]\n",
    "\n",
    "nlp.get_pipe(\"medspacy_target_matcher\").add(target_rules)\n",
    "\n",
    "def span_overlaps_any(span_start, span_end, ents):\n",
    "    \"\"\"Devuelve True si el span [span_start, span_end) solapa con alguna entidad en ents.\"\"\"\n",
    "    for e in ents:\n",
    "        # entidad e cubre [e.start, e.end)\n",
    "        if not (span_end <= e.start or span_start >= e.end):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ---  Tu componente que busca valores adjetivales ---\n",
    "@Language.component(\"find_marker_value_bidirectional_safe\")\n",
    "def find_marker_value_bidirectional_safe(doc):\n",
    "    current_ents = list(doc.ents)  # entidades originales\n",
    "    new_ents = []\n",
    "\n",
    "    # √≠ndices ocupados por entidades originales (r√°pido para checks)\n",
    "    occupied_tokens = set()\n",
    "    for e in current_ents:\n",
    "        occupied_tokens.update(range(e.start, e.end))\n",
    "\n",
    "    for ent in current_ents:\n",
    "        if ent.label_ not in [\"MARKER\", \"BMI\", \"GLUCOSE\", \"AGE\"]:\n",
    "            continue\n",
    "\n",
    "        # -------- B√öSQUEDA HACIA ADELANTE --------\n",
    "        window_start = ent.end\n",
    "        window_end = min(ent.end + 5, len(doc))\n",
    "        for token in doc[window_start:window_end]:\n",
    "            # candidate span: [token.i, token.i+1) o incluir adv antes si procede\n",
    "            start = token.i\n",
    "            if token.i - 1 >= 0 and doc[token.i - 1].pos_ == \"ADV\":\n",
    "                start = token.i - 1\n",
    "            end = token.i + 1\n",
    "\n",
    "            # comprobar condiciones pos/num\n",
    "            is_value = token.like_num or token.pos_ == \"ADJ\" or token.lower_ in {\"high\",\"low\",\"normal\",\"elevated\",\"increased\",\"decreased\"}\n",
    "            if not is_value:\n",
    "                continue\n",
    "\n",
    "            # NO crear si solapa con entidades existentes\n",
    "            if span_overlaps_any(start, end, current_ents):\n",
    "                # si solapa, saltamos (no intentamos recortar autom√°ticamente)\n",
    "                continue\n",
    "\n",
    "            # NO solapar con nuevas entidades que ya hemos a√±adido\n",
    "            if span_overlaps_any(start, end, new_ents):\n",
    "                continue\n",
    "\n",
    "            new_ents.append(Span(doc, start, end, label=f\"{ent.label_}_VALUE\"))\n",
    "            break\n",
    "\n",
    "        # -------- B√öSQUEDA HACIA ATR√ÅS --------\n",
    "        window_start_back = max(ent.start - 5, 0)\n",
    "        window_end_back = ent.start\n",
    "        # iteramos en orden inverso para pillar el adjetivo m√°s cercano\n",
    "        for token in reversed(doc[window_start_back:window_end_back]):\n",
    "            start = token.i\n",
    "            # incluir adv antes si hay (ej. \"very high\")\n",
    "            if token.i - 1 >= 0 and doc[token.i - 1].pos_ == \"ADV\":\n",
    "                start = token.i - 1\n",
    "            end = token.i + 1\n",
    "\n",
    "            is_value = token.like_num or token.pos_ == \"ADJ\" or token.lower_ in {\"high\",\"low\",\"normal\",\"elevated\",\"increased\",\"decreased\"}\n",
    "            if not is_value:\n",
    "                continue\n",
    "\n",
    "            # evitar solapamientos con entidades originales/nuevas\n",
    "            if span_overlaps_any(start, end, current_ents):\n",
    "                continue\n",
    "            if span_overlaps_any(start, end, new_ents):\n",
    "                continue\n",
    "\n",
    "            new_ents.append(Span(doc, start, end, label=f\"{ent.label_}_VALUE\"))\n",
    "            break\n",
    "\n",
    "    # Busca las unidades de la concentraci√≥n de glucosa\n",
    "    extra_ents = []\n",
    "    for ent in new_ents:\n",
    "        if ent.label_ == \"GLUCOSE_VALUE\":\n",
    "            try:\n",
    "                float(ent.text)\n",
    "                #print(f\"'{ent.text}' es un n√∫mero float.\")\n",
    "\n",
    "                possible_units = {\"mg/dl\", \"mg/dL\", \"mg / dL\", \"mmol/L\", \"mmol/l\", \"g/L\", \"mg%\", \"mg dl\", \"mg per dL\", \"mg\"}\n",
    "                \n",
    "                # Despu√©s de detectar que 'ent.text' es un n√∫mero:\n",
    "                if ent.end < len(doc):\n",
    "                    next_token = doc[ent.end]\n",
    "                \n",
    "                    # üîç Intentamos varias formas:\n",
    "                    combined = next_token.text\n",
    "                    # incluye tambi√©n dos tokens seguidos (\"mg\" + \"/\" + \"dL\")\n",
    "                    if ent.end + 2 < len(doc):\n",
    "                        combined2 = next_token.text + doc[ent.end + 1].text + doc[ent.end + 2].text\n",
    "                        combined2 = combined2.replace(\" \", \"\")\n",
    "                    else:\n",
    "                        combined2 = \"\"\n",
    "                \n",
    "                    # Normalizar a min√∫sculas y sin espacios\n",
    "                    combined = combined.lower().replace(\" \", \"\")\n",
    "                    if combined in possible_units or combined2.lower() in possible_units:\n",
    "                        #print(f\" ‚Üí Se detecta unidad '{combined}'\")\n",
    "                        new_label = \"GLUCOSE_UNITS\"\n",
    "                        extra_ents.append(Span(doc, next_token.i, min(len(doc), next_token.i + 3), label=new_label))\n",
    "\n",
    "            except ValueError:\n",
    "                # No es float\n",
    "                pass\n",
    "    \n",
    "    # Combina y filtra solapamientos (filter_spans tambi√©n ayuda si hay igualdad/duplas)\n",
    "    all_ents = current_ents + new_ents + extra_ents\n",
    "    try:\n",
    "        doc.ents = filter_spans(all_ents)\n",
    "    except Exception as e:\n",
    "        # diagn√≥stico detallado para depuraci√≥n: imprime spans problem√°ticos\n",
    "        print(\"ERROR al asignar doc.ents:\", e)\n",
    "        print(\"Entidades actuales:\")\n",
    "        for e0 in current_ents:\n",
    "            print(f\"  - {e0.text} [{e0.start},{e0.end}) {e0.label_}\")\n",
    "        print(\"Entidades nuevas propuestas:\")\n",
    "        for e1 in new_ents:\n",
    "            print(f\"  - {e1.text} [{e1.start},{e1.end}) {e1.label_}\")\n",
    "        # re-raise para que no se silencie\n",
    "        raise\n",
    "\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.666128Z",
     "iopub.status.idle": "2025-11-04T18:01:34.666488Z",
     "shell.execute_reply": "2025-11-04T18:01:34.666326Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.666313Z"
    }
   },
   "outputs": [],
   "source": [
    "from medspacy.context import ConTextRule\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Asegurar ConText justo despu√©s del target matcher\n",
    "# ---------------------------------------------------\n",
    "if \"medspacy_context\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"medspacy_context\", after=\"medspacy_target_matcher\")\n",
    "else:\n",
    "    nlp.remove_pipe(\"medspacy_context\")\n",
    "    nlp.add_pipe(\"medspacy_context\", after=\"medspacy_target_matcher\")\n",
    "\n",
    "# ------------------------------------\n",
    "# Reglas ConText extra para la estructura de las medical notes\n",
    "# ------------------------------------\n",
    "context = nlp.get_pipe(\"medspacy_context\")\n",
    "context.add([\n",
    "    # Negaciones gen√©ricas √∫tiles\n",
    "    ConTextRule(\"no\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"without\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"free of\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"denies\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=8),\n",
    "    ConTextRule(\"denies any\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=8),\n",
    "    ConTextRule(\"never\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"no history of\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=10),\n",
    "    ConTextRule(\"negative for\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=6),\n",
    "\n",
    "    # ‚Äúnon ‚Ä¶‚Äù (variaciones t√≠picas)\n",
    "    ConTextRule(\"non\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=5),\n",
    "    ConTextRule(\"non-\", \"NEGATED_EXISTENCE\", direction=\"FORWARD\", max_scope=5),\n",
    "    ConTextRule(\"non smoking\", \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "    ConTextRule(\"non-smoking\", \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "    ConTextRule(\"non smoker\", \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "    ConTextRule(\"non-smoker\", \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "    ConTextRule(\"non smokin\", \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "\n",
    "    # Hist√≥rico (no actual) ‚Äî cuenta como presente para ENFERMEDADES pero no para SMOKE\n",
    "    ConTextRule(\"past\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"former\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"formerly\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=6),\n",
    "    ConTextRule(\"ex-smoker\", \"HISTORICAL\", direction=\"BIDIRECTIONAL\", max_scope=3),\n",
    "    ConTextRule(\"history of\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=8),\n",
    "    ConTextRule(\"hx of\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=8),\n",
    "    ConTextRule(\"h/o\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=8),\n",
    "    ConTextRule(\"PMH of\", \"HISTORICAL\", direction=\"FORWARD\", max_scope=8),\n",
    "])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# votaci√≥n por regex del SMOKE en funci√≥n de lo detectado\n",
    "# ----------------------------------------------------\n",
    "NEG_SMOKE_RE = re.compile(\n",
    "    r\"\\b(non[-\\s]smok\\w|never\\s+smok\\w*|denies\\s+smok\\w*|no\\s+(history\\s+of\\s+)?smok\\w*|not\\s+a\\s+smoker)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "HIST_SMOKE_RE = re.compile(\n",
    "    r\"\\b(former(ly)?\\s+smok\\w*|past\\s+smok\\w*|ex[-\\s]smok\\w|history\\s+of\\s+smok\\w*)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "POS_SMOKE_RE = re.compile(\n",
    "    r\"\\b(current(ly)?\\s+a?\\s*smok\\w*|smokes\\b|smoking\\b|is\\s+a\\s+smoker|smoker\\b)\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "@Language.component(\"smoking_flag_classifier\")\n",
    "def smoking_flag_classifier(doc):\n",
    "    text = doc.text.lower()\n",
    "    doc._.smoking_vote = None  # -1=neg, 0=hist, 1=pos, None=indeterminado\n",
    "\n",
    "    if NEG_SMOKE_RE.search(text):\n",
    "        doc._.smoking_vote = -1\n",
    "        return doc\n",
    "    if HIST_SMOKE_RE.search(text):\n",
    "        doc._.smoking_vote = 1   \n",
    "        return doc\n",
    "    if POS_SMOKE_RE.search(text):\n",
    "        if not NEG_SMOKE_RE.search(text):\n",
    "            doc._.smoking_vote = 1\n",
    "            return doc\n",
    "    return doc\n",
    "\n",
    "# Registrar extensi√≥n de Doc para el voto\n",
    "if not spacy.tokens.Doc.has_extension(\"smoking_vote\"):\n",
    "    spacy.tokens.Doc.set_extension(\"smoking_vote\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.667418Z",
     "iopub.status.idle": "2025-11-04T18:01:34.667683Z",
     "shell.execute_reply": "2025-11-04T18:01:34.667566Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.667554Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"find_marker_value_bidirectional_safe\", after=\"medspacy_target_matcher\")\n",
    "nlp.add_pipe(\"smoking_flag_classifier\", after=\"medspacy_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.668471Z",
     "iopub.status.idle": "2025-11-04T18:01:34.668770Z",
     "shell.execute_reply": "2025-11-04T18:01:34.668656Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.668640Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 8) Funciones auxiliares para los flags\n",
    "# --------------------------------------------\n",
    "# Para SMOKE (actual): requerimos NO negado, NO familiar, NO hist√≥rico, NO hipot√©tico\n",
    "def is_asserted_current(ent):\n",
    "    return not getattr(ent._, \"is_negated\", False) \\\n",
    "        and not getattr(ent._, \"is_family\", False) \\\n",
    "        and not getattr(ent._, \"is_historical\", False) \\\n",
    "        and not getattr(ent._, \"is_hypothetical\", False)\n",
    "\n",
    "# Para ENFERMEDADES: contar como presente si NO est√° negado, NO familiar, NO hipot√©tico\n",
    "def is_present_condition(ent):\n",
    "    return not getattr(ent._, \"is_negated\", False) \\\n",
    "        and not getattr(ent._, \"is_family\", False) \\\n",
    "        and not getattr(ent._, \"is_hypothetical\", False)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 9) C√°lculo de flags (combina voto y entidades ConText)\n",
    "# ----------------------------------------------------------\n",
    "def compute_smoker_flag(doc):\n",
    "    # Prioridad al voto del regex si existe\n",
    "    if doc._.smoking_vote == -1:\n",
    "        return 0\n",
    "    if doc._.smoking_vote == 0:\n",
    "        return 0\n",
    "    if doc._.smoking_vote == 1:\n",
    "        return 1\n",
    "    # Si no hubo voto, usa entidades + ConText (solo actuales)\n",
    "    return 1 if any(ent.label_ == \"SMOKE\" and is_asserted_current(ent) for ent in doc.ents) else 0\n",
    "\n",
    "def compute_hypertension_flag(doc):\n",
    "    # Cuenta hist√≥rico como presente mientras no est√© negado/familiar/hipot√©tico\n",
    "    return 1 if any(ent.label_ == \"HYPERTENSION\" and is_present_condition(ent) for ent in doc.ents) else 0\n",
    "\n",
    "def compute_heart_disease_flag(doc):\n",
    "    # Cuenta hist√≥rico como presente mientras no est√© negado/familiar/hipot√©tico\n",
    "    return 1 if any(ent.label_ == \"HEART_DISEASE\" and is_present_condition(ent) for ent in doc.ents) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.669730Z",
     "iopub.status.idle": "2025-11-04T18:01:34.669969Z",
     "shell.execute_reply": "2025-11-04T18:01:34.669862Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.669852Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Pipeline actualizado:\", nlp.pipe_names)\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    if lista[i][0]==4941:\n",
    "        text = lista[i][2]\n",
    "        doc = nlp(text)\n",
    "        print(f\"Textos encontrados en el paciente con ID {lista[i][0]}:\")\n",
    "        for ent in doc.ents:\n",
    "            print(f\"Texto: '{ent.text}', Etiqueta: '{ent.label_}'\\n\")\n",
    "    \n",
    "        smoker_flag = compute_smoker_flag(doc)\n",
    "        hypertension_flag = compute_hypertension_flag(doc)\n",
    "        heart_disease_flag = compute_heart_disease_flag(doc)\n",
    "    \n",
    "        print(f\"--> Fumador: {smoker_flag}\")\n",
    "        print(f\"--> Hypertension: {hypertension_flag}\")\n",
    "        print(f\"--> Heart disease: {heart_disease_flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.670853Z",
     "iopub.status.idle": "2025-11-04T18:01:34.671226Z",
     "shell.execute_reply": "2025-11-04T18:01:34.671038Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.671023Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "\n",
    "data_rows = []\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    patient_id = lista[i][0]\n",
    "    has_diabetes = lista[i][1]\n",
    "    text = lista[i][2]\n",
    "    doc = nlp(text)\n",
    "\n",
    "    smoker_flag = compute_smoker_flag(doc)\n",
    "    hypertension_flag = compute_hypertension_flag(doc)\n",
    "    heart_disease_flag = compute_heart_disease_flag(doc)\n",
    "    \n",
    "    # Creamos un diccionario con el ID y luego rellenamos con las entidades\n",
    "    row = {\"patient_id\": patient_id, \"has_diabetes\": has_diabetes, \"smoker\": smoker_flag, \"hypertension\": hypertension_flag, \"heart_disease\": heart_disease_flag}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        label = ent.label_\n",
    "        value = ent.text\n",
    "\n",
    "        # Si esa etiqueta a√∫n no est√° guardada, la a√±adimos\n",
    "        # (as√≠ no se sobrescribe si ya tiene valor)\n",
    "        if label not in row and label in [\"GENDER\", \"BMI_VALUE\", \"MARKER_VALUE\", \"GLUCOSE_VALUE\", \"GLUCOSE_UNITS\"]:\n",
    "            row[label] = value\n",
    "        if label not in row and label in [\"AGE_VALUE\"]:\n",
    "            if not isinstance(value, (int, float)):\n",
    "                row[label] = w2n.word_to_num(value)\n",
    "            else:\n",
    "                row[label] = value\n",
    "    data_rows.append(row)\n",
    "\n",
    "# Convertimos a DataFrame (las columnas se crear√°n autom√°ticamente)\n",
    "df = pd.DataFrame(data_rows)\n",
    "\n",
    "# --- Mapeos definidos ---\n",
    "bmi_map = {\n",
    "    \"low\": 16,\n",
    "    \"decreased\": 16\n",
    "    \"normal\": 22.5,\n",
    "    \"high\": 30,\n",
    "    \"increased\": 30,\n",
    "    \"elevated\": 30\n",
    "}\n",
    "\n",
    "marker_map = {\n",
    "    \"low\": 4,\n",
    "    \"decreased\": 4,\n",
    "    \"normal\": 5,\n",
    "    \"high\": 7,\n",
    "    \"increased\": 7,\n",
    "    \"elevated\": 7\n",
    "}\n",
    "\n",
    "glucose_map = {\n",
    "    \"low\": 100,\n",
    "    \"low\": 100,\n",
    "    \"normal\": 150,\n",
    "    \"high\": 250,\n",
    "    \"increased\": 250,\n",
    "    \"elevated\": 250\n",
    "}\n",
    "\n",
    "def convert_value(val, mapping):\n",
    "    \"\"\"\n",
    "    Convierte texto seg√∫n el mapeo. \n",
    "    Si ya es num√©rico o convertible, devuelve el n√∫mero.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    val_str = str(val).strip().lower()\n",
    "    # Si es texto conocido ‚Üí asignar n√∫mero\n",
    "    if val_str in mapping:\n",
    "        return mapping[val_str]\n",
    "    # Si es n√∫mero ‚Üí devolver como float\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# --- Aplicar conversiones ---\n",
    "df[\"BMI_VALUE\"] = df[\"BMI_VALUE\"].apply(lambda x: convert_value(x, bmi_map))\n",
    "df[\"MARKER_VALUE\"] = df[\"MARKER_VALUE\"].apply(lambda x: convert_value(x, marker_map))\n",
    "df[\"GLUCOSE_VALUE\"] = df[\"GLUCOSE_VALUE\"].apply(lambda x: convert_value(x, glucose_map))\n",
    "\n",
    "# Exportamos\n",
    "df.to_csv(\"entidades_por_paciente.csv\", index=False, sep=\";\")\n",
    "print(\" CSV generado: entidades_por_paciente.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T18:17:05.379408Z",
     "iopub.status.busy": "2025-11-04T18:17:05.378730Z",
     "iopub.status.idle": "2025-11-04T18:17:07.731254Z",
     "shell.execute_reply": "2025-11-04T18:17:07.730289Z",
     "shell.execute_reply.started": "2025-11-04T18:17:05.379382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=757, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=757, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features='log2', min_samples_leaf=2,\n",
       "                       min_samples_split=12, n_estimators=757, random_state=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#  # Cargar el archivo CSV\n",
    "df = pd.read_csv(\"/kaggle/input/train-2/dataset_2.csv\", sep=\";\")\n",
    "\n",
    "#  # Eliminar columnas que no aportan informaci√≥n\n",
    "df = df.drop(columns=[\"patient_id\", \"GLUCOSE_UNITS\"])\n",
    "\n",
    "#  # Codificar la variable categ√≥rica GENDER\n",
    "if \"GENDER\" in df.columns:\n",
    "    df[\"GENDER\"] = LabelEncoder().fit_transform(df[\"GENDER\"].astype(str))\n",
    "\n",
    "#  # Convertir todas las columnas posibles a formato num√©rico (valores no num√©ricos se transforman en NaN)\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "#  # Rellenar los valores faltantes con la media de cada columna num√©rica\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "#  # Separar las variables independientes (X) de la variable objetivo (y)\n",
    "X_train = df.drop(columns=[\"has_diabetes\"])\n",
    "y_train = df[\"has_diabetes\"]\n",
    "\n",
    "#  # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0, random_state=42)\n",
    "\n",
    "#  # Entrenar el modelo Random Forest con los par√°metros definidos\n",
    "clf = RandomForestClassifier(n_estimators=431, min_samples_leaf=1, min_samples_split=8, max_depth=8, random_state=0, max_features=None)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#  # Evaluar el rendimiento del modelo con el conjunto de prueba\n",
    "#accuracy = clf.score(X_test, y_test)\n",
    "#print(f\" Precisi√≥n en test = {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Mostrar un informe completo de clasificaci√≥n si se desea\n",
    "#y_pred = clf.predict(X_test)\n",
    "#print(\"\\nReporte de clasificaci√≥n:\")\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de datos del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.674660Z",
     "iopub.status.idle": "2025-11-04T18:01:34.675024Z",
     "shell.execute_reply": "2025-11-04T18:01:34.674852Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.674836Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time # Buena pr√°ctica a√±adir una pausa\n",
    "\n",
    "BASE_URL = \"https://api.hackupm2025.workers.dev\"\n",
    "train_list_endpoint = \"/api/v1/patients/test\"\n",
    "i = 1\n",
    "lista=[]\n",
    "while True:\n",
    "    try:\n",
    "        params_consulta = {\n",
    "            'page': i,\n",
    "            'limit': 20,\n",
    "        }\n",
    "\n",
    "        url_completa = BASE_URL + train_list_endpoint\n",
    "\n",
    "        response = requests.get(url_completa, params=params_consulta, timeout=10)\n",
    "\n",
    "        # 5. Comprueba si la petici√≥n fue exitosa (c√≥digo 200)\n",
    "        if response.status_code == 200:\n",
    "            datos = response.json()\n",
    "            # print(f\"URL final solicitada: {response.url}\")\n",
    "            for fila in datos['data']:\n",
    "                lista.append((fila['patient_id'], fila['medical_note']))\n",
    "            # (Opcional) Muestra cu√°ntos datos reales vinieron\n",
    "            # Asumiendo que los datos est√°n en una clave 'data')\n",
    "            \n",
    "            # ---\n",
    "            # 1. CORRECCI√ìN DE SINTAXIS Y L√ìGICA:\n",
    "            #    Mueve el 'break' DENTRO del if de √©xito.\n",
    "            #    Corrige la sintaxis de acceso al diccionario.\n",
    "            #    Compara con el booleano 'False', no con el string \"false\".\n",
    "            # ---\n",
    "            if not datos[\"pagination\"][\"hasNextPage\"]:\n",
    "                print(\"No hay m√°s p√°ginas. Saliendo del bucle.\")\n",
    "                break # ¬°√âxito! Salimos del bucle.\n",
    "            \n",
    "            # Si llegamos aqu√≠, es que hay m√°s p√°ginas. Incrementamos.\n",
    "            i += 1\n",
    "\n",
    "        else:\n",
    "            # 2. CORRECCI√ìN DE ERROR:\n",
    "            #    Si la API da un error (ej. 404, 500), debemos parar el bucle.\n",
    "            print(f\"Error: La API devolvi√≥ el c√≥digo {response.status_code}\")\n",
    "            print(f\"Respuesta: {response.text}\")\n",
    "            print(\"Saliendo del bucle debido a un error de la API.\")\n",
    "            break # Salimos del bucle si la API falla\n",
    "\n",
    "    # 3. CORRECCI√ìN DE EXCEPCI√ìN:\n",
    "    #    La sintaxis 'Exception or ...' es incorrecta.\n",
    "    #    Es mejor capturar la excepci√≥n base de 'requests'.\n",
    "    except requests.exceptions.RequestException as e: \n",
    "        print(f\"Error de conexi√≥n o red: {e}\")\n",
    "        print(f\"No se pudo conectar a '{BASE_URL}'. Saliendo del bucle.\")\n",
    "        break # Salimos si hay un error de conexi√≥n\n",
    "\n",
    "    # A√±ade una peque√±a pausa para no saturar la API\n",
    "    #time.sleep(0.5)\n",
    "\n",
    "print(\"¬°Datos de prueba obtenidos con √©xito!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicaci√≥n del NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.676190Z",
     "iopub.status.idle": "2025-11-04T18:01:34.676571Z",
     "shell.execute_reply": "2025-11-04T18:01:34.676401Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.676384Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "\n",
    "data_rows = []\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    patient_id = lista[i][0]\n",
    "    text = lista[i][1]\n",
    "    doc = nlp(text)\n",
    "\n",
    "    smoker_flag = compute_smoker_flag(doc)\n",
    "    hypertension_flag = compute_hypertension_flag(doc)\n",
    "    heart_disease_flag = compute_heart_disease_flag(doc)\n",
    "    \n",
    "    # Creamos un diccionario con el ID y luego rellenamos con las entidades\n",
    "    row = {\"patient_id\": patient_id, \"smoker\": smoker_flag, \"hypertension\": hypertension_flag, \"heart_disease\": heart_disease_flag}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        label = ent.label_\n",
    "        value = ent.text\n",
    "\n",
    "        # Si esa etiqueta a√∫n no est√° guardada, la a√±adimos\n",
    "        # (as√≠ no se sobrescribe si ya tiene valor)\n",
    "        if label not in row and label in [\"GENDER\", \"BMI_VALUE\", \"MARKER_VALUE\", \"GLUCOSE_VALUE\", \"GLUCOSE_UNITS\"]:\n",
    "            row[label] = value\n",
    "        if label not in row and label in [\"AGE_VALUE\"]:\n",
    "            if not isinstance(value, (int, float)):\n",
    "                row[label] = w2n.word_to_num(value)\n",
    "            else:\n",
    "                row[label] = value\n",
    "    data_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-04T18:01:34.677697Z",
     "iopub.status.idle": "2025-11-04T18:01:34.678051Z",
     "shell.execute_reply": "2025-11-04T18:01:34.677882Z",
     "shell.execute_reply.started": "2025-11-04T18:01:34.677867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convertimos a DataFrame (las columnas se crear√°n autom√°ticamente)\n",
    "df = pd.DataFrame(data_rows)\n",
    "\n",
    "# --- Mapeos definidos ---\n",
    "bmi_map = {\n",
    "    \"low\": 16,\n",
    "    \"decreased\": 16,\n",
    "    \"normal\": 22.5,\n",
    "    \"high\": 30,\n",
    "    \"increased\": 30,\n",
    "    \"elevated\": 30\n",
    "}\n",
    "\n",
    "marker_map = {\n",
    "    \"low\": 4,\n",
    "    \"decreased\": 4,\n",
    "    \"normal\": 5,\n",
    "    \"high\": 7,\n",
    "    \"increased\": 7,\n",
    "    \"elevated\": 7\n",
    "}\n",
    "\n",
    "glucose_map = {\n",
    "    \"low\": 100,\n",
    "    \"low\": 100,\n",
    "    \"normal\": 150,\n",
    "    \"high\": 250,\n",
    "    \"increased\": 250,\n",
    "    \"elevated\": 250\n",
    "}\n",
    "\n",
    "def convert_value(val, mapping):\n",
    "    \"\"\"\n",
    "    Convierte texto seg√∫n el mapeo. \n",
    "    Si ya es num√©rico o convertible, devuelve el n√∫mero.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    val_str = str(val).strip().lower()\n",
    "    # Si es texto conocido ‚Üí asignar n√∫mero\n",
    "    if val_str in mapping:\n",
    "        return mapping[val_str]\n",
    "    # Si es n√∫mero ‚Üí devolver como float\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# --- Aplicar conversiones ---\n",
    "df[\"BMI_VALUE\"] = df[\"BMI_VALUE\"].apply(lambda x: convert_value(x, bmi_map))\n",
    "df[\"MARKER_VALUE\"] = df[\"MARKER_VALUE\"].apply(lambda x: convert_value(x, marker_map))\n",
    "df[\"GLUCOSE_VALUE\"] = df[\"GLUCOSE_VALUE\"].apply(lambda x: convert_value(x, glucose_map))\n",
    "\n",
    "# Exportamos\n",
    "df.to_csv(\"test.csv\", index=False, sep=\";\")\n",
    "print(\" CSV generado: test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferencia del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T18:17:20.459090Z",
     "iopub.status.busy": "2025-11-04T18:17:20.458763Z",
     "iopub.status.idle": "2025-11-04T18:17:20.546578Z",
     "shell.execute_reply": "2025-11-04T18:17:20.545521Z",
     "shell.execute_reply.started": "2025-11-04T18:17:20.459064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patient_id  has_diabetes\n",
      "0  patient_37551             0\n",
      "1  patient_24430             0\n",
      "2  patient_89346             0\n",
      "3  patient_88818             1\n",
      "4  patient_00139             0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/test-1/test.csv\", sep=\";\")\n",
    "\n",
    "patient_ids = df[\"patient_id\"].tolist()\n",
    "\n",
    "if \"GENDER\" in df.columns:\n",
    "    df[\"GENDER\"] = LabelEncoder().fit_transform(df[\"GENDER\"].astype(str))\n",
    "\n",
    "#  # Convertir todas las columnas posibles a formato num√©rico (valores no num√©ricos se transforman en NaN)\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "#  # Rellenar los valores faltantes con la media de cada columna num√©rica\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "X_test = df.drop(columns=[\"patient_id\", \"GLUCOSE_UNITS\"])\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"patient_id\": [f\"patient_{str(p).zfill(5)}\" for p in patient_ids],\n",
    "    \"has_diabetes\": y_pred\n",
    "})\n",
    "print(pred_df.head())\n",
    "pred_df.to_csv(\"predicciones.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizaci√≥n de par√°metros con Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T18:12:49.130871Z",
     "iopub.status.busy": "2025-11-04T18:12:49.130532Z",
     "iopub.status.idle": "2025-11-04T18:15:57.487636Z",
     "shell.execute_reply": "2025-11-04T18:15:57.486222Z",
     "shell.execute_reply.started": "2025-11-04T18:12:49.130846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-04 18:12:49,137] A new study created in memory with name: no-name-82ab72d4-7f64-4a01-9c0f-528c9a020343\n",
      "[I 2025-11-04 18:12:53,129] Trial 0 finished with value: 0.8569999999999999 and parameters: {'n_estimators': 605, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:12:56,028] Trial 1 finished with value: 0.8513333333333333 and parameters: {'n_estimators': 512, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:12:58,083] Trial 2 finished with value: 0.835 and parameters: {'n_estimators': 668, 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 20, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:00,434] Trial 3 finished with value: 0.8483333333333333 and parameters: {'n_estimators': 754, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 16, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:02,532] Trial 4 finished with value: 0.8496666666666667 and parameters: {'n_estimators': 597, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 17, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:04,102] Trial 5 finished with value: 0.8516666666666667 and parameters: {'n_estimators': 516, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:08,269] Trial 6 finished with value: 0.8506666666666667 and parameters: {'n_estimators': 923, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:09,971] Trial 7 finished with value: 0.765 and parameters: {'n_estimators': 672, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:12,132] Trial 8 finished with value: 0.8486666666666666 and parameters: {'n_estimators': 701, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:14,931] Trial 9 finished with value: 0.8556666666666667 and parameters: {'n_estimators': 742, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:15,992] Trial 10 finished with value: 0.8489999999999999 and parameters: {'n_estimators': 206, 'max_depth': 30, 'min_samples_split': 20, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:17,431] Trial 11 finished with value: 0.8556666666666667 and parameters: {'n_estimators': 378, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:20,785] Trial 12 finished with value: 0.8546666666666667 and parameters: {'n_estimators': 904, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:22,131] Trial 13 finished with value: 0.8566666666666666 and parameters: {'n_estimators': 374, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:23,032] Trial 14 finished with value: 0.8546666666666667 and parameters: {'n_estimators': 248, 'max_depth': 13, 'min_samples_split': 20, 'min_samples_leaf': 12, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:24,407] Trial 15 finished with value: 0.8556666666666667 and parameters: {'n_estimators': 378, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:24,740] Trial 16 finished with value: 0.8493333333333334 and parameters: {'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 14, 'max_features': None}. Best is trial 0 with value: 0.8569999999999999.\n",
      "[I 2025-11-04 18:13:26,209] Trial 17 finished with value: 0.8576666666666667 and parameters: {'n_estimators': 377, 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 17 with value: 0.8576666666666667.\n",
      "[I 2025-11-04 18:13:28,173] Trial 18 finished with value: 0.8573333333333334 and parameters: {'n_estimators': 464, 'max_depth': 22, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 0.8576666666666667.\n",
      "[I 2025-11-04 18:13:29,792] Trial 19 finished with value: 0.8513333333333334 and parameters: {'n_estimators': 270, 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 17 with value: 0.8576666666666667.\n",
      "[I 2025-11-04 18:13:31,493] Trial 20 finished with value: 0.8583333333333334 and parameters: {'n_estimators': 438, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:33,196] Trial 21 finished with value: 0.8570000000000001 and parameters: {'n_estimators': 438, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:34,993] Trial 22 finished with value: 0.856 and parameters: {'n_estimators': 455, 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:36,228] Trial 23 finished with value: 0.8583333333333334 and parameters: {'n_estimators': 312, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:36,744] Trial 24 finished with value: 0.8526666666666666 and parameters: {'n_estimators': 151, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:37,994] Trial 25 finished with value: 0.8566666666666666 and parameters: {'n_estimators': 313, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 20 with value: 0.8583333333333334.\n",
      "[I 2025-11-04 18:13:38,673] Trial 26 finished with value: 0.8596666666666667 and parameters: {'n_estimators': 172, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:38,892] Trial 27 finished with value: 0.848 and parameters: {'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:39,406] Trial 28 finished with value: 0.854 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:40,134] Trial 29 finished with value: 0.8483333333333333 and parameters: {'n_estimators': 135, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:41,185] Trial 30 finished with value: 0.852 and parameters: {'n_estimators': 306, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:42,066] Trial 31 finished with value: 0.8576666666666667 and parameters: {'n_estimators': 217, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:43,220] Trial 32 finished with value: 0.8556666666666666 and parameters: {'n_estimators': 326, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:45,161] Trial 33 finished with value: 0.8526666666666666 and parameters: {'n_estimators': 575, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 26 with value: 0.8596666666666667.\n",
      "[I 2025-11-04 18:13:46,547] Trial 34 finished with value: 0.8603333333333333 and parameters: {'n_estimators': 376, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 34 with value: 0.8603333333333333.\n",
      "[I 2025-11-04 18:13:48,253] Trial 35 finished with value: 0.8576666666666667 and parameters: {'n_estimators': 431, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 34 with value: 0.8603333333333333.\n",
      "[I 2025-11-04 18:13:50,370] Trial 36 finished with value: 0.8596666666666666 and parameters: {'n_estimators': 556, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 34 with value: 0.8603333333333333.\n",
      "[I 2025-11-04 18:13:52,147] Trial 37 finished with value: 0.8543333333333333 and parameters: {'n_estimators': 559, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 34 with value: 0.8603333333333333.\n",
      "[I 2025-11-04 18:13:54,450] Trial 38 finished with value: 0.8366666666666666 and parameters: {'n_estimators': 630, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 34 with value: 0.8603333333333333.\n",
      "[I 2025-11-04 18:13:56,406] Trial 39 finished with value: 0.8610000000000001 and parameters: {'n_estimators': 509, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:13:58,204] Trial 40 finished with value: 0.8583333333333334 and parameters: {'n_estimators': 510, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:00,129] Trial 41 finished with value: 0.8569999999999999 and parameters: {'n_estimators': 511, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:02,320] Trial 42 finished with value: 0.8546666666666667 and parameters: {'n_estimators': 641, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:04,534] Trial 43 finished with value: 0.8573333333333334 and parameters: {'n_estimators': 553, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:07,540] Trial 44 finished with value: 0.859 and parameters: {'n_estimators': 782, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:10,726] Trial 45 finished with value: 0.8593333333333333 and parameters: {'n_estimators': 840, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:14,302] Trial 46 finished with value: 0.8586666666666667 and parameters: {'n_estimators': 867, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:17,190] Trial 47 finished with value: 0.847 and parameters: {'n_estimators': 965, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:19,719] Trial 48 finished with value: 0.8533333333333334 and parameters: {'n_estimators': 727, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 15, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:21,757] Trial 49 finished with value: 0.854 and parameters: {'n_estimators': 666, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:26,188] Trial 50 finished with value: 0.856 and parameters: {'n_estimators': 807, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:29,152] Trial 51 finished with value: 0.858 and parameters: {'n_estimators': 798, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:32,024] Trial 52 finished with value: 0.8586666666666667 and parameters: {'n_estimators': 807, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:35,453] Trial 53 finished with value: 0.859 and parameters: {'n_estimators': 862, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:38,436] Trial 54 finished with value: 0.8596666666666666 and parameters: {'n_estimators': 769, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:42,023] Trial 55 finished with value: 0.8556666666666666 and parameters: {'n_estimators': 976, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:44,882] Trial 56 finished with value: 0.848 and parameters: {'n_estimators': 850, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 17, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:47,067] Trial 57 finished with value: 0.8553333333333333 and parameters: {'n_estimators': 595, 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:49,836] Trial 58 finished with value: 0.8573333333333334 and parameters: {'n_estimators': 702, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:53,182] Trial 59 finished with value: 0.8569999999999999 and parameters: {'n_estimators': 901, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:55,202] Trial 60 finished with value: 0.8143333333333334 and parameters: {'n_estimators': 760, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 'log2'}. Best is trial 39 with value: 0.8610000000000001.\n",
      "[I 2025-11-04 18:14:57,931] Trial 61 finished with value: 0.8613333333333334 and parameters: {'n_estimators': 757, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:14:59,483] Trial 62 finished with value: 0.86 and parameters: {'n_estimators': 406, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:01,279] Trial 63 finished with value: 0.8586666666666667 and parameters: {'n_estimators': 483, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:02,670] Trial 64 finished with value: 0.8576666666666667 and parameters: {'n_estimators': 363, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:03,281] Trial 65 finished with value: 0.8513333333333333 and parameters: {'n_estimators': 101, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:04,926] Trial 66 finished with value: 0.858 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:05,953] Trial 67 finished with value: 0.8593333333333334 and parameters: {'n_estimators': 271, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:07,303] Trial 68 finished with value: 0.858 and parameters: {'n_estimators': 394, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:08,723] Trial 69 finished with value: 0.855 and parameters: {'n_estimators': 351, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:10,563] Trial 70 finished with value: 0.8603333333333333 and parameters: {'n_estimators': 483, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:12,096] Trial 71 finished with value: 0.8603333333333333 and parameters: {'n_estimators': 402, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:13,886] Trial 72 finished with value: 0.8569999999999999 and parameters: {'n_estimators': 475, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:15,266] Trial 73 finished with value: 0.8526666666666666 and parameters: {'n_estimators': 392, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:17,005] Trial 74 finished with value: 0.8506666666666667 and parameters: {'n_estimators': 495, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 13, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:19,028] Trial 75 finished with value: 0.858 and parameters: {'n_estimators': 530, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:20,714] Trial 76 finished with value: 0.8563333333333333 and parameters: {'n_estimators': 450, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:22,268] Trial 77 finished with value: 0.8596666666666667 and parameters: {'n_estimators': 405, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:23,324] Trial 78 finished with value: 0.8486666666666666 and parameters: {'n_estimators': 188, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:24,836] Trial 79 finished with value: 0.86 and parameters: {'n_estimators': 411, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:26,086] Trial 80 finished with value: 0.8570000000000001 and parameters: {'n_estimators': 338, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:27,623] Trial 81 finished with value: 0.86 and parameters: {'n_estimators': 411, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:28,660] Trial 82 finished with value: 0.855 and parameters: {'n_estimators': 288, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:30,146] Trial 83 finished with value: 0.8596666666666666 and parameters: {'n_estimators': 408, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:31,843] Trial 84 finished with value: 0.8610000000000001 and parameters: {'n_estimators': 451, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:33,872] Trial 85 finished with value: 0.8576666666666667 and parameters: {'n_estimators': 527, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:35,326] Trial 86 finished with value: 0.8513333333333333 and parameters: {'n_estimators': 461, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:36,687] Trial 87 finished with value: 0.8516666666666666 and parameters: {'n_estimators': 428, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:38,104] Trial 88 finished with value: 0.86 and parameters: {'n_estimators': 372, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:39,810] Trial 89 finished with value: 0.8546666666666667 and parameters: {'n_estimators': 483, 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 11, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:41,090] Trial 90 finished with value: 0.8570000000000001 and parameters: {'n_estimators': 336, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:42,454] Trial 91 finished with value: 0.8573333333333334 and parameters: {'n_estimators': 375, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:44,061] Trial 92 finished with value: 0.8593333333333333 and parameters: {'n_estimators': 419, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:45,742] Trial 93 finished with value: 0.859 and parameters: {'n_estimators': 448, 'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:47,004] Trial 94 finished with value: 0.8573333333333334 and parameters: {'n_estimators': 357, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:48,463] Trial 95 finished with value: 0.8586666666666667 and parameters: {'n_estimators': 390, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:49,634] Trial 96 finished with value: 0.8593333333333333 and parameters: {'n_estimators': 307, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:51,675] Trial 97 finished with value: 0.8596666666666667 and parameters: {'n_estimators': 532, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:54,369] Trial 98 finished with value: 0.8530000000000001 and parameters: {'n_estimators': 498, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 61 with value: 0.8613333333333334.\n",
      "[I 2025-11-04 18:15:55,224] Trial 99 finished with value: 0.8446666666666666 and parameters: {'n_estimators': 248, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 19, 'max_features': 'log2'}. Best is trial 61 with value: 0.8613333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaci√≥n finalizada.\n",
      "Mejor score (accuracy media en CV): 0.8613333333333334\n",
      "Mejores par√°metros encontrados:\n",
      "{'n_estimators': 757, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/207218405.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Eval√∫a (¬°ahora s√≠!) en el conjunto de Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mfinal_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nPrecisi√≥n final del modelo optimizado en TEST = {final_accuracy * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- (Asumimos que X_train, y_train, X_test, Y_test ya existen) ---\n",
    "# X_train, y_train = ...\n",
    "# X_test, Y_test = ...\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# 1. DEFINE LA FUNCI√ìN OBJETIVO\n",
    "# Optuna llamar√° a esta funci√≥n en cada \"intento\" (trial)\n",
    "def objective(trial):\n",
    "    \n",
    "    # --- A. Sugiere los hiperpar√°metros a probar ---\n",
    "    # Usamos 'suggest_int' para enteros y 'suggest_float' para decimales\n",
    "    # 'log=True' es bueno para par√°metros que var√≠an exponencialmente\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    # Tambi√©n podemos probar 'max_features' que mencionaste antes\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # --- B. Crea el clasificador con esos par√°metros ---\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=0  # Fija el random_state para reproducibilidad\n",
    "    )\n",
    "\n",
    "    # --- C. Eval√∫a el modelo usando Cross-Validation ---\n",
    "    # Usamos SOLO X_train y y_train. \n",
    "    # cv=3 significa 3-fold cross-validation.\n",
    "    score = cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "    accuracy = score.mean()\n",
    "    \n",
    "    # --- D. Devuelve el score que Optuna debe maximizar ---\n",
    "    return accuracy\n",
    "\n",
    "# 2. CREA Y EJECUTA EL ESTUDIO\n",
    "# direction=\"maximize\" porque queremos la mayor accuracy posible\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# n_trials=100 significa que probar√° 100 combinaciones de par√°metros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 3. MUESTRA LOS RESULTADOS\n",
    "print(\"Optimizaci√≥n finalizada.\")\n",
    "print(\"Mejor score (accuracy media en CV):\", study.best_value)\n",
    "print(\"Mejores par√°metros encontrados:\")\n",
    "print(study.best_params)\n",
    "\n",
    "\n",
    "# --- 4. PASO FINAL: Entrena el modelo final y eval√∫a en Test ---\n",
    "\n",
    "# Obtiene los mejores par√°metros del estudio\n",
    "best_params = study.best_params\n",
    "\n",
    "# Crea el clasificador final con esos par√°metros\n",
    "final_clf = RandomForestClassifier(**best_params, random_state=0)\n",
    "\n",
    "# Entrena con TODOS los datos de entrenamiento\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Eval√∫a (¬°ahora s√≠!) en el conjunto de Test\n",
    "final_accuracy = final_clf.score(X_test, Y_test)\n",
    "\n",
    "print(f\"\\nPrecisi√≥n final del modelo optimizado en TEST = {final_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8651124,
     "sourceId": 13613025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8651223,
     "sourceId": 13613147,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8651700,
     "sourceId": 13613767,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8651931,
     "sourceId": 13614095,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8651985,
     "sourceId": 13614161,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
